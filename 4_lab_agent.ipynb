{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meldoner/hostfiles/blob/main/4_lab_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cef0b06",
      "metadata": {
        "id": "3cef0b06"
      },
      "source": [
        "# HTTP Malware Detection — Colab-Friendly Plan\n",
        "\n",
        "This notebook builds an end-to-end baseline for the TCP-flow classification challenge while respecting Google Colab's 12 GB RAM limit and the dataset sizes (≈8.5 M train / 4 M test rows). The strategy:\n",
        "\n",
        "1. **Memory-aware loading** – enforce compact dtypes (int16) and optionally limit rows via `DEBUG_ROWS` for quick experiments.\n",
        "2. **Packet merging** – merge consecutive packets with the same direction when `|length| > 1200`, using NumPy/Numba for vectorized speed.\n",
        "3. **Feature stack** – keep the merged 30-length sequences and add lightweight statistics (abs sums, counts, ratios, etc.).\n",
        "4. **Modeling** – LightGBM multiclass with class-balancing, stratified validation slice, and early stopping.\n",
        "5. **Inference** – reuse the exact preprocessing to score the 4 M-row test set and write a submission file.\n",
        "\n",
        "All heavy steps are wrapped into reusable functions so the workflow can be executed end-to-end or step-by-step in Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1OjobuA8I-F6fe-8sxNcwrwLovqRQoqsn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnEMYGpch4Jr",
        "outputId": "be8ff1cc-80a4-415a-c3a9-d7b0faadb907"
      },
      "id": "NnEMYGpch4Jr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1OjobuA8I-F6fe-8sxNcwrwLovqRQoqsn\n",
            "From (redirected): https://drive.google.com/uc?id=1OjobuA8I-F6fe-8sxNcwrwLovqRQoqsn&confirm=t&uuid=e16dfdf3-249f-4977-8e2b-320416308570\n",
            "To: /content/whos-talking-classify-the-app-by-its-packets.zip\n",
            "100% 305M/305M [00:05<00:00, 59.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip whos-talking-classify-the-app-by-its-packets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNSTW8UriDeU",
        "outputId": "1eea6b55-6ed1-44bc-d288-fa4d478fbbed"
      },
      "id": "jNSTW8UriDeU",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  whos-talking-classify-the-app-by-its-packets.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "64deca92",
      "metadata": {
        "id": "64deca92"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import gc\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, Iterable, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "try:\n",
        "    from numba import njit, prange\n",
        "    NUMBA_AVAILABLE = True\n",
        "except ImportError:  # pragma: no cover\n",
        "    NUMBA_AVAILABLE = False\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ea3bc334",
      "metadata": {
        "id": "ea3bc334"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = Path('.')  # update to Path('/content/drive/MyDrive/...') in Colab if files live on Drive\n",
        "TRAIN_CSV = DATA_DIR / 'train.csv'\n",
        "TEST_CSV = DATA_DIR / 'test.csv'\n",
        "SAMPLE_SUB = DATA_DIR / 'sample_submission.csv'\n",
        "\n",
        "N_PACKETS = 30\n",
        "MERGE_THRESHOLD = 1200\n",
        "#DEBUG_ROWS = int(os.environ.get('DEBUG_ROWS', '0'))  # set non-zero in Colab for quick dry-runs\n",
        "DEBUG_ROWS = 500000  # set non-zero in Colab for quick dry-runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "91e6af2a",
      "metadata": {
        "id": "91e6af2a"
      },
      "outputs": [],
      "source": [
        "def build_feature_columns(n_packets: int = N_PACKETS) -> List[str]:\n",
        "    return [f'tcp_len_{idx + 1}' for idx in range(n_packets)]\n",
        "\n",
        "def load_dataframe(\n",
        "    path: Path,\n",
        "    n_rows: Optional[int] = None,\n",
        "    with_target: bool = False,\n",
        "    extra_columns: Optional[List[str]] = None,\n",
        ") -> pd.DataFrame:\n",
        "    feature_cols = build_feature_columns()\n",
        "    dtype_map = {col: np.int16 for col in feature_cols}\n",
        "    usecols = feature_cols.copy()\n",
        "    if with_target:\n",
        "        usecols = ['app_service'] + usecols\n",
        "    if extra_columns:\n",
        "        usecols = extra_columns + usecols\n",
        "    dtypes = dtype_map if not with_target else {**dtype_map, 'app_service': 'category'}\n",
        "    df = pd.read_csv(path, usecols=usecols, dtype=dtypes, nrows=n_rows)\n",
        "    return df\n",
        "\n",
        "\n",
        "def mem_in_gb(df: pd.DataFrame) -> float:\n",
        "    return df.memory_usage(deep=True).sum() / 1024 ** 3\n",
        "\n",
        "\n",
        "def report_mem(df: pd.DataFrame, label: str) -> None:\n",
        "    print(f\"{label} memory footprint: {mem_in_gb(df):.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "67c5b3fc",
      "metadata": {
        "id": "67c5b3fc"
      },
      "outputs": [],
      "source": [
        "def _merge_packets_python(data: np.ndarray, threshold: int) -> np.ndarray:\n",
        "    n_rows, n_cols = data.shape\n",
        "    merged = np.zeros_like(data)\n",
        "    for i in range(n_rows):\n",
        "        write_idx = 0\n",
        "        merging = False\n",
        "        running_sum = 0\n",
        "        running_sign = 0\n",
        "        for j in range(n_cols):\n",
        "            val = int(data[i, j])\n",
        "            if val == 0:\n",
        "                if merging and write_idx < n_cols:\n",
        "                    merged[i, write_idx] = running_sum\n",
        "                    write_idx += 1\n",
        "                break\n",
        "            abs_val = abs(val)\n",
        "            sign = 1 if val > 0 else -1\n",
        "            if abs_val > threshold:\n",
        "                if merging and sign == running_sign:\n",
        "                    running_sum += val\n",
        "                else:\n",
        "                    if merging and write_idx < n_cols:\n",
        "                        merged[i, write_idx] = running_sum\n",
        "                        write_idx += 1\n",
        "                    merging = True\n",
        "                    running_sum = val\n",
        "                    running_sign = sign\n",
        "            else:\n",
        "                if merging and write_idx < n_cols:\n",
        "                    merged[i, write_idx] = running_sum\n",
        "                    write_idx += 1\n",
        "                    merging = False\n",
        "                    running_sum = 0\n",
        "                    running_sign = 0\n",
        "                if write_idx < n_cols:\n",
        "                    merged[i, write_idx] = val\n",
        "                    write_idx += 1\n",
        "        if merging and write_idx < n_cols:\n",
        "            merged[i, write_idx] = running_sum\n",
        "    return merged\n",
        "\n",
        "\n",
        "if NUMBA_AVAILABLE:\n",
        "    @njit(parallel=True)\n",
        "    def _merge_packets_numba(data: np.ndarray, threshold: int) -> np.ndarray:  # pragma: no cover\n",
        "        n_rows, n_cols = data.shape\n",
        "        merged = np.zeros_like(data)\n",
        "        for i in prange(n_rows):\n",
        "            write_idx = 0\n",
        "            merging = False\n",
        "            running_sum = 0\n",
        "            running_sign = 0\n",
        "            for j in range(n_cols):\n",
        "                val = int(data[i, j])\n",
        "                if val == 0:\n",
        "                    if merging and write_idx < n_cols:\n",
        "                        merged[i, write_idx] = running_sum\n",
        "                        write_idx += 1\n",
        "                    break\n",
        "                abs_val = abs(val)\n",
        "                sign = 1 if val > 0 else -1\n",
        "                if abs_val > threshold:\n",
        "                    if merging and sign == running_sign:\n",
        "                        running_sum += val\n",
        "                    else:\n",
        "                        if merging and write_idx < n_cols:\n",
        "                            merged[i, write_idx] = running_sum\n",
        "                            write_idx += 1\n",
        "                        merging = True\n",
        "                        running_sum = val\n",
        "                        running_sign = sign\n",
        "                else:\n",
        "                    if merging and write_idx < n_cols:\n",
        "                        merged[i, write_idx] = running_sum\n",
        "                        write_idx += 1\n",
        "                        merging = False\n",
        "                        running_sum = 0\n",
        "                        running_sign = 0\n",
        "                    if write_idx < n_cols:\n",
        "                        merged[i, write_idx] = val\n",
        "                        write_idx += 1\n",
        "            if merging and write_idx < n_cols:\n",
        "                merged[i, write_idx] = running_sum\n",
        "        return merged\n",
        "else:\n",
        "    _merge_packets_numba = None\n",
        "\n",
        "\n",
        "def merge_packets(data: np.ndarray, threshold: int = MERGE_THRESHOLD) -> np.ndarray:\n",
        "    func = _merge_packets_numba if NUMBA_AVAILABLE and _merge_packets_numba is not None else _merge_packets_python\n",
        "    return func(data, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9cc3d5f7",
      "metadata": {
        "id": "9cc3d5f7"
      },
      "outputs": [],
      "source": [
        "def engineer_sequence_features(seq: np.ndarray) -> Tuple[np.ndarray, List[str]]:\n",
        "    seq = seq.astype(np.float32)\n",
        "    abs_seq = np.abs(seq)\n",
        "\n",
        "    non_zero = (seq != 0).sum(axis=1)\n",
        "    non_zero_safe = np.maximum(non_zero, 1)\n",
        "    pos_mask = seq > 0\n",
        "    neg_mask = seq < 0\n",
        "\n",
        "    features = {\n",
        "        'non_zero_packets': non_zero,\n",
        "        'pos_packets': pos_mask.sum(axis=1),\n",
        "        'neg_packets': neg_mask.sum(axis=1),\n",
        "        'pos_ratio': pos_mask.sum(axis=1) / non_zero_safe,\n",
        "        'neg_ratio': neg_mask.sum(axis=1) / non_zero_safe,\n",
        "        'abs_sum': abs_seq.sum(axis=1),\n",
        "        'abs_mean': abs_seq.sum(axis=1) / non_zero_safe,\n",
        "        'abs_max': abs_seq.max(axis=1),\n",
        "        'seq_sum': seq.sum(axis=1),\n",
        "        'seq_mean': seq.sum(axis=1) / non_zero_safe,\n",
        "        'seq_std': seq.std(axis=1),\n",
        "        'pos_sum': np.clip(seq, 0, None).sum(axis=1),\n",
        "        'neg_sum': np.clip(seq, None, 0).sum(axis=1),\n",
        "        'energy': (seq ** 2).sum(axis=1),\n",
        "    }\n",
        "\n",
        "    # first and last non-zero packets (if any)\n",
        "    mask_non_zero = seq != 0\n",
        "    first_idx = mask_non_zero.argmax(axis=1)\n",
        "    first_vals = seq[np.arange(seq.shape[0]), first_idx]\n",
        "    first_vals[non_zero == 0] = 0\n",
        "\n",
        "    reversed_mask = mask_non_zero[:, ::-1]\n",
        "    last_idx = reversed_mask.argmax(axis=1)\n",
        "    last_vals = seq[np.arange(seq.shape[0]), seq.shape[1] - 1 - last_idx]\n",
        "    last_vals[non_zero == 0] = 0\n",
        "\n",
        "    features.update({'first_packet': first_vals, 'last_packet': last_vals, 'zero_padding_ratio': 1.0 - non_zero / seq.shape[1]})\n",
        "\n",
        "    feat_matrix = np.vstack([values for values in features.values()]).T.astype(np.float32)\n",
        "    feat_names = list(features.keys())\n",
        "    return feat_matrix, feat_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "97c9f5dc",
      "metadata": {
        "id": "97c9f5dc"
      },
      "outputs": [],
      "source": [
        "def build_design_matrix(df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:\n",
        "    seq_cols = build_feature_columns()\n",
        "    seq_array = df[seq_cols].to_numpy(dtype=np.int16, copy=False)\n",
        "    merged_seq = merge_packets(seq_array)\n",
        "    merged_seq = merged_seq.astype(np.float32)\n",
        "\n",
        "    seq_feature_names = [f'merged_{col}' for col in seq_cols]\n",
        "    seq_features = merged_seq\n",
        "\n",
        "    stat_features, stat_names = engineer_sequence_features(merged_seq)\n",
        "    design_matrix = np.hstack([seq_features, stat_features]).astype(np.float32)\n",
        "    feature_names = seq_feature_names + stat_names\n",
        "    return design_matrix, feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7d2f74d8",
      "metadata": {
        "id": "7d2f74d8"
      },
      "outputs": [],
      "source": [
        "def make_class_weights(labels: np.ndarray) -> Dict[int, float]:\n",
        "    classes = np.unique(labels)\n",
        "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
        "    return {cls: weight for cls, weight in zip(classes, weights)}\n",
        "\n",
        "\n",
        "def build_sample_weight(labels: np.ndarray, weight_map: Dict[int, float]) -> np.ndarray:\n",
        "    return np.array([weight_map[label] for label in labels], dtype=np.float32)\n",
        "\n",
        "\n",
        "def train_lightgbm(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_valid: np.ndarray,\n",
        "    y_valid: np.ndarray,\n",
        "    feature_names: List[str],\n",
        "    sample_weight_train: Optional[np.ndarray] = None,\n",
        "    sample_weight_valid: Optional[np.ndarray] = None,\n",
        "    num_classes: int = 1,\n",
        "    num_boost_round: int = 5000,\n",
        "    early_stopping_rounds: int = 100,\n",
        ") -> lgb.Booster:\n",
        "    params = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': num_classes,\n",
        "        'learning_rate': 0.05,\n",
        "        'num_leaves': 96,\n",
        "        'min_data_in_leaf': 256,\n",
        "        'feature_fraction': 0.8,\n",
        "        'bagging_fraction': 0.8,\n",
        "        'bagging_freq': 2,\n",
        "        'max_depth': -1,\n",
        "        'metric': ['multi_logloss'],\n",
        "        'verbosity': -1,\n",
        "        'force_row_wise': True,\n",
        "    }\n",
        "\n",
        "    train_set = lgb.Dataset(X_train, label=y_train, weight=sample_weight_train, feature_name=feature_names)\n",
        "    valid_set = lgb.Dataset(X_valid, label=y_valid, weight=sample_weight_valid, feature_name=feature_names)\n",
        "\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_set,\n",
        "        valid_sets=[train_set, valid_set],\n",
        "        valid_names=['train', 'valid'],\n",
        "        num_boost_round=num_boost_round,\n",
        "        early_stopping_rounds=early_stopping_rounds,\n",
        "        verbose_eval=100,\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "756cf635",
      "metadata": {
        "id": "756cf635"
      },
      "outputs": [],
      "source": [
        "def predict_labels(model: lgb.Booster, X: np.ndarray, label_encoder: LabelEncoder) -> np.ndarray:\n",
        "    proba = model.predict(X, num_iteration=model.best_iteration or model.current_iteration())\n",
        "    if isinstance(proba, list):\n",
        "        proba = np.vstack(proba).T\n",
        "    preds_idx = np.argmax(proba, axis=1)\n",
        "    return label_encoder.inverse_transform(preds_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f8497890",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "f8497890",
        "outputId": "4ab1b46a-971b-4fe6-ac0c-dce559d9f793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train raw memory footprint: 0.03 GB\n",
            "CPU times: user 3.75 s, sys: 490 ms, total: 4.24 s\n",
            "Wall time: 5.03 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  app_service  tcp_len_1  tcp_len_2  tcp_len_3  tcp_len_4  tcp_len_5  \\\n",
              "0           1       1448        379      -1448      -1448      -1202   \n",
              "1           1       1448        313      -1448      -1410       -522   \n",
              "2           1       1448        379      -1448      -1448         -2   \n",
              "3           1       1448        315      -1448      -1448         -2   \n",
              "4           1       1448        367      -1448      -1448       -477   \n",
              "\n",
              "   tcp_len_6  tcp_len_7  tcp_len_8  tcp_len_9  ...  tcp_len_21  tcp_len_22  \\\n",
              "0      -1448      -1192         80         92  ...           0           0   \n",
              "1         64         92        298       -250  ...           0           0   \n",
              "2       -256         64       1172       -574  ...       -1448       -1448   \n",
              "3      -1448        -27         64         92  ...           0           0   \n",
              "4         80         92        637       -303  ...           0           0   \n",
              "\n",
              "   tcp_len_23  tcp_len_24  tcp_len_25  tcp_len_26  tcp_len_27  tcp_len_28  \\\n",
              "0           0           0           0           0           0           0   \n",
              "1           0           0           0           0           0           0   \n",
              "2       -1448       -1448       -1448       -1448       -1448       -1448   \n",
              "3           0           0           0           0           0           0   \n",
              "4           0           0           0           0           0           0   \n",
              "\n",
              "   tcp_len_29  tcp_len_30  \n",
              "0           0           0  \n",
              "1           0           0  \n",
              "2       -1448        -638  \n",
              "3           0           0  \n",
              "4           0           0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69a4c019-d284-4506-9289-f66dd52ea617\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_service</th>\n",
              "      <th>tcp_len_1</th>\n",
              "      <th>tcp_len_2</th>\n",
              "      <th>tcp_len_3</th>\n",
              "      <th>tcp_len_4</th>\n",
              "      <th>tcp_len_5</th>\n",
              "      <th>tcp_len_6</th>\n",
              "      <th>tcp_len_7</th>\n",
              "      <th>tcp_len_8</th>\n",
              "      <th>tcp_len_9</th>\n",
              "      <th>...</th>\n",
              "      <th>tcp_len_21</th>\n",
              "      <th>tcp_len_22</th>\n",
              "      <th>tcp_len_23</th>\n",
              "      <th>tcp_len_24</th>\n",
              "      <th>tcp_len_25</th>\n",
              "      <th>tcp_len_26</th>\n",
              "      <th>tcp_len_27</th>\n",
              "      <th>tcp_len_28</th>\n",
              "      <th>tcp_len_29</th>\n",
              "      <th>tcp_len_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1448</td>\n",
              "      <td>379</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1202</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1192</td>\n",
              "      <td>80</td>\n",
              "      <td>92</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1448</td>\n",
              "      <td>313</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1410</td>\n",
              "      <td>-522</td>\n",
              "      <td>64</td>\n",
              "      <td>92</td>\n",
              "      <td>298</td>\n",
              "      <td>-250</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1448</td>\n",
              "      <td>379</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-2</td>\n",
              "      <td>-256</td>\n",
              "      <td>64</td>\n",
              "      <td>1172</td>\n",
              "      <td>-574</td>\n",
              "      <td>...</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1448</td>\n",
              "      <td>315</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-27</td>\n",
              "      <td>64</td>\n",
              "      <td>92</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1448</td>\n",
              "      <td>367</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-1448</td>\n",
              "      <td>-477</td>\n",
              "      <td>80</td>\n",
              "      <td>92</td>\n",
              "      <td>637</td>\n",
              "      <td>-303</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69a4c019-d284-4506-9289-f66dd52ea617')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69a4c019-d284-4506-9289-f66dd52ea617 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69a4c019-d284-4506-9289-f66dd52ea617');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aafce869-6ac3-4451-9c57-eed6c7948570\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aafce869-6ac3-4451-9c57-eed6c7948570')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aafce869-6ac3-4451-9c57-eed6c7948570 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "%%time\n",
        "train_df = load_dataframe(TRAIN_CSV, n_rows=DEBUG_ROWS or None, with_target=True)\n",
        "report_mem(train_df, 'Train raw')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d33b7feb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d33b7feb",
        "outputId": "fcee9259-620d-4285-af2e-7f7ac5bd8461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (500000, 47)\n",
            "Unique classes: 9\n",
            "CPU times: user 2.89 s, sys: 296 ms, total: 3.19 s\n",
            "Wall time: 3.36 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13812"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "%%time\n",
        "X_all, feature_names = build_design_matrix(train_df.drop(columns=['app_service']))\n",
        "label_encoder = LabelEncoder()\n",
        "y_all = label_encoder.fit_transform(train_df['app_service'])\n",
        "weight_map = make_class_weights(y_all)\n",
        "sample_weight_all = build_sample_weight(y_all, weight_map)\n",
        "print(f\"Feature matrix shape: {X_all.shape}\")\n",
        "print(f\"Unique classes: {len(label_encoder.classes_)}\")\n",
        "del train_df\n",
        "gc.collect();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "bba08b76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bba08b76",
        "outputId": "a34cab39-0139-47c0-8d21-2c1248273318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train split: (475000, 47), Valid split: (25000, 47)\n"
          ]
        }
      ],
      "source": [
        "VAL_SIZE = 0.05\n",
        "\n",
        "X_train, X_valid, y_train, y_valid, w_train, w_valid = train_test_split(\n",
        "    X_all,\n",
        "    y_all,\n",
        "    sample_weight_all,\n",
        "    test_size=VAL_SIZE,\n",
        "    random_state=42,\n",
        "    stratify=y_all,\n",
        ")\n",
        "print(f\"Train split: {X_train.shape}, Valid split: {X_valid.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "83594a11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "83594a11",
        "outputId": "f5f7ce02-8882-4020-b0cf-6c5da25e0356"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4051263853.py\u001b[0m in \u001b[0;36mtrain_lightgbm\u001b[0;34m(X_train, y_train, X_valid, y_valid, feature_names, sample_weight_train, sample_weight_valid, num_classes, num_boost_round, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     model = lgb.train(\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model = train_lightgbm(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_valid=X_valid,\n",
        "    y_valid=y_valid,\n",
        "    feature_names=feature_names,\n",
        "    sample_weight_train=w_train,\n",
        "    sample_weight_valid=w_valid,\n",
        "    num_classes=len(label_encoder.classes_),\n",
        ")\n",
        "\n",
        "valid_pred = predict_labels(model, X_valid, label_encoder)\n",
        "valid_f1 = f1_score(label_encoder.inverse_transform(y_valid), valid_pred, average='macro')\n",
        "print(f\"Validation macro F1: {valid_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410279f1",
      "metadata": {
        "id": "410279f1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "best_iteration = model.best_iteration or model.current_iteration()\n",
        "print(f\"Training final model on all data for {best_iteration} boosting rounds\")\n",
        "train_set_full = lgb.Dataset(X_all, label=y_all, weight=sample_weight_all, feature_name=feature_names)\n",
        "final_model = lgb.train(\n",
        "    {**model.params, 'objective': 'multiclass', 'num_class': len(label_encoder.classes_)},\n",
        "    train_set_full,\n",
        "    num_boost_round=best_iteration,\n",
        "    verbose_eval=100,\n",
        ")\n",
        "\n",
        "del X_train, X_valid, y_train, y_valid, w_train, w_valid\n",
        "gc.collect();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cfe7a60",
      "metadata": {
        "id": "2cfe7a60"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "test_df = load_dataframe(TEST_CSV, n_rows=DEBUG_ROWS or None, extra_columns=['id'])\n",
        "report_mem(test_df, 'Test raw')\n",
        "X_test, _ = build_design_matrix(test_df.drop(columns=['id']))\n",
        "test_predictions = predict_labels(final_model, X_test, label_encoder)\n",
        "submission_df = pd.DataFrame({'id': test_df['id'], 'app_service': test_predictions})\n",
        "submission_path = DATA_DIR / 'submission.csv'\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "print(f\"Submission saved to {submission_path} with shape {submission_df.shape}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}